# AI 모델 통합 계획 (향후 개발)

## 🎯 개요
현재 통계 분석 플랫폼에 Ollama 기반 로컬 AI 모델을 통합하여 사용자 경험을 개선하는 계획

## 📋 현재 상태
- ✅ 기본 통계 분석 시스템 구현 완료
- ✅ SciPy 기반 정확한 계산 엔진 구현
- ✅ 다중비교 보정 기능 구현
- ✅ 상세한 결과 해석 가이드 시스템 구현
- ⏸️ AI 모델 통합은 **향후 개발** 예정

## 🤖 AI 모델 통합 목표

### 핵심 개선 영역
1. **분석 방법 자동 추천** - 데이터 특성 분석 → 최적 통계 방법 제안
2. **자동 데이터 품질 검사** - 이상치, 결측값, 분포 이상 자동 탐지
3. **지능적 결과 해석** - 맥락을 고려한 개인화된 해석 제공
4. **동적 워크플로 생성** - 분석 결과에 따른 다음 단계 자동 제안

### 예상 효과
- 🕐 분석 시간: **50-80% 단축**
- 🎯 정확도: **90%+ 향상** (초보자 → 전문가급)
- 📈 사용자 만족도: **크게 향상**
- 🎓 학습 효과: **통계 지식 없이도 전문 분석 가능**

## 🛠️ 기술 스택 (계획)

### AI 모델
- **Ollama**: 로컬 AI 모델 실행 환경
- **추천 모델들**:
  - `gemma3:270m` - **최경량 모델 (최우선 테스트용)** ⭐
  - `gemma3:2b` - 경량 모델 (성능 비교용)

### 아키텍처 (방법2: 기능별 분리)
```
lib/
├── statistics.ts              # 현재 기본 시스템
├── pyodide-stats-engine.ts   # SciPy 엔진
├── ai/                       # AI 기능 (향후 추가)
│   ├── ollama-client.ts      # Ollama API 클라이언트
│   ├── analysis-recommender.ts # 분석 방법 추천
│   ├── data-validator.ts     # 자동 데이터 검증
│   └── result-interpreter.ts # 지능적 결과 해석
├── adapters/                 # 어댑터 패턴
│   ├── statistics-adapter.ts # 기본 방식
│   └── ai-statistics-adapter.ts # AI 방식
└── config.ts                 # 모드 전환 설정
```

## ⚠️ 구현 시 고려사항

### 사용자 부담
- 📥 **모델 다운로드**: 1-4GB 크기 (gemma2:2b ≈ 1.6GB)
- 🖥️ **시스템 요구사항**: 최소 8GB RAM 권장
- ⚡ **속도**: 로컬 모델은 클라우드 API보다 느림

### 기술적 복잡성
- 🔧 Ollama 서버 설치 및 설정 필요
- 🔄 모델 관리 (다운로드, 업데이트, 삭제)
- 🐛 오프라인 환경에서의 디버깅 어려움

## 📅 단계별 개발 계획 (향후)

### Phase 0: 사전 테스트 및 검증 (1주) ⚠️ **필수 선행 단계**
- [ ] **gemma3:270m 성능 테스트**
  - [ ] 기본 설치 및 연결 테스트
  - [ ] 분석 방법 추천 정확도 측정 (최소 70% 목표)
  - [ ] 응답 속도 측정 (5초 이내 목표)
  - [ ] 메모리 사용량 모니터링 (4GB 이하 목표)
- [ ] **시뮬레이션 테스트**
  - [ ] 10개 샘플 데이터셋으로 추천 성능 검증
  - [ ] 다양한 데이터 타입별 응답 품질 평가
  - [ ] 한국어 응답 품질 확인
  - [ ] 오프라인 환경 동작 확인
- [ ] **성능 기준 통과 시에만 다음 단계 진행**
  - ✅ 통과: Phase 1 진행
  - ❌ 미달: 더 큰 모델 (gemma3:2b) 검토 또는 기본 시스템 유지

### Phase 1: 기본 AI 통합 (2-3주)
- [ ] Ollama 클라이언트 구현
- [ ] 기본 분석 추천 기능
- [ ] 설정 기반 AI/기본 모드 전환
- [ ] **gemma3:270m vs gemma3:2b 성능 비교**

### Phase 2: 고급 AI 기능 (3-4주)
- [ ] 자동 데이터 품질 검사
- [ ] 지능적 결과 해석
- [ ] 사용자 피드백 학습 시스템
- [ ] **실제 사용자 테스트 및 피드백 수집**

### Phase 3: 최적화 및 안정화 (2주)
- [ ] 성능 최적화
- [ ] 오류 처리 강화
- [ ] 사용자 가이드 작성

## 🎯 현재 우선순위: 기본 기능 완성

**AI 모델 통합은 현재 기본 시스템이 완성된 후 진행 예정**

현재 진행 중인 작업:
1. ✅ 다중비교 보정 시스템 구현 완료
2. ✅ 상세 결과 해석 가이드 시스템 완료  
3. ✅ 한글 파일명 시스템 완료
4. 🔄 **다음 단계**: 실제 분석 UI 구현, 데이터 업로드, 시각화

---

**최종 목표**: 기본 시스템 완성 → AI 모델로 사용자 경험 대폭 개선

---

## 🧪 상세 시뮬레이션 테스트 계획

### 테스트 시나리오 (gemma2:270m 대상)

#### 1️⃣ **분석 방법 추천 테스트**
```
입력: "20명 학생의 수학점수와 과학점수 데이터"
기대 출력: "상관분석(Pearson) 추천, 신뢰도 80%+"
실제 출력: [테스트 결과 기록]

입력: "A약(15명), B약(12명), 대조군(18명)의 혈압 변화 데이터" 
기대 출력: "일원분산분석(ANOVA) 추천, 신뢰도 85%+"
실제 출력: [테스트 결과 기록]

입력: "치료 전후 20명 환자의 우울척도 점수"
기대 출력: "대응표본 t-검정 추천, 신뢰도 90%+"
실제 출력: [테스트 결과 기록]
```

#### 2️⃣ **한국어 응답 품질 테스트**
```
프롬프트: "이 데이터에 가장 적합한 통계 분석 방법을 추천해주세요"
기대: 자연스러운 한국어 + 전문 용어 적절히 사용
실제: [응답 품질 평가 1-5점]

프롬프트: "결과를 쉽게 설명해주세요"  
기대: 비전문가도 이해 가능한 설명
실제: [응답 품질 평가 1-5점]
```

#### 3️⃣ **성능 기준선**
- ⚡ **속도**: 응답 시간 5초 이내 (로컬 실행)
- 🎯 **정확도**: 추천 방법 정확도 70% 이상
- 💾 **메모리**: 4GB RAM 이하 사용
- 🌐 **오프라인**: 인터넷 연결 없이 완전 동작

#### 4️⃣ **실패 기준 및 대안**
```
만약 gemma2:270m이 다음 중 하나라도 실패하면:
❌ 정확도 < 70% → gemma2:2b 시도
❌ 응답 속도 > 10초 → 다른 모델 검토  
❌ 메모리 > 6GB → 기본 시스템 유지
❌ 한국어 품질 낮음 → 프롬프트 튜닝 후 재시도
```

### 📊 테스트 결과 기록 양식
```
모델: gemma2:270m
테스트 날짜: [YYYY-MM-DD]
테스트 환경: [시스템 사양]

=== 성능 측정 ===
평균 응답시간: __초
메모리 사용량: __GB  
추천 정확도: __%

=== 품질 평가 ===
한국어 자연스러움: _/5점
전문 용어 정확성: _/5점  
설명 명확성: _/5점

=== 최종 결론 ===  
□ 통과 - Phase 1 진행
□ 미달 - [구체적 이유 및 대안]
```

**중요**: 코드 작성 전 반드시 이 시뮬레이션 테스트를 완료하고 결과를 문서화할 것!