# ğŸ—ï¸ Technical Architecture Specification

**ë²„ì „**: 2.0  
**ì—…ë°ì´íŠ¸**: 2025-09-12  
**í”„ë¡œì íŠ¸**: statistical-platform

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ê°œìš”

### ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì„±ë„
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Frontend Layer            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Next.js 15 + TypeScript + shadcn  â”‚
â”‚  â”œâ”€â”€ App Router (React 19)          â”‚
â”‚  â”œâ”€â”€ Server Components (RSC)        â”‚
â”‚  â”œâ”€â”€ Client Components (ìƒí˜¸ì‘ìš©)   â”‚
â”‚  â””â”€â”€ API Routes (ë‚´ë¶€ API)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Computation Layer          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Pyodide + Web Workers             â”‚
â”‚  â”œâ”€â”€ Python 3.11 (WebAssembly)     â”‚
â”‚  â”œâ”€â”€ scipy.stats (í†µê³„ ì—°ì‚°)        â”‚
â”‚  â”œâ”€â”€ numpy (ìˆ˜ì¹˜ ê³„ì‚°)              â”‚
â”‚  â”œâ”€â”€ pandas (ë°ì´í„° ì²˜ë¦¬)           â”‚
â”‚  â””â”€â”€ Web Workers (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Data Layer               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Browser Storage + File System     â”‚
â”‚  â”œâ”€â”€ IndexedDB (ëŒ€ìš©ëŸ‰ ë°ì´í„°)      â”‚
â”‚  â”œâ”€â”€ LocalStorage (ì„¤ì •/ìºì‹œ)       â”‚
â”‚  â”œâ”€â”€ File API (íŒŒì¼ ì—…ë¡œë“œ)         â”‚
â”‚  â””â”€â”€ Tauri FS (ë°ìŠ¤í¬íƒ‘ íŒŒì¼ ì ‘ê·¼)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Frontend ì•„í‚¤í…ì²˜

### Next.js 15 App Router êµ¬ì¡°
```
statistical-platform/             # í”„ë¡œì íŠ¸ ë£¨íŠ¸
â”œâ”€â”€ app/                          # Next.js 15 App Router
â”‚   â”œâ”€â”€ globals.css               # ì „ì—­ ìŠ¤íƒ€ì¼ (Tailwind CSS)
â”‚   â”œâ”€â”€ layout.tsx                # ë£¨íŠ¸ ë ˆì´ì•„ì›ƒ
â”‚   â”œâ”€â”€ page.tsx                  # í™ˆí˜ì´ì§€ (ìºëŸ¬ì…€ UI)
â”‚   â”œâ”€â”€ favicon.ico               # íŒŒë¹„ì½˜
â”‚   â””â”€â”€ (dashboard)/              # ëŒ€ì‹œë³´ë“œ ë¼ìš°íŠ¸ ê·¸ë£¹
â”‚       â”œâ”€â”€ layout.tsx            # ëŒ€ì‹œë³´ë“œ ë ˆì´ì•„ì›ƒ
â”‚       â”œâ”€â”€ dashboard/            # ë©”ì¸ ëŒ€ì‹œë³´ë“œ
â”‚       â”‚   â””â”€â”€ page.tsx          
â”‚       â”œâ”€â”€ analysis/             # í†µê³„ ë¶„ì„
â”‚       â”‚   â”œâ”€â”€ page.tsx          # ë¶„ì„ ë©”ì¸
â”‚       â”‚   â””â”€â”€ [type]/           # ë™ì  ë¼ìš°íŠ¸
â”‚       â”œâ”€â”€ smart-analysis/       # AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ë¶„ì„
â”‚       â”‚   â””â”€â”€ page.tsx          
â”‚       â”œâ”€â”€ data/                 # ë°ì´í„° ê´€ë¦¬
â”‚       â”‚   â””â”€â”€ page.tsx          
â”‚       â”œâ”€â”€ results/              # ë¶„ì„ ê²°ê³¼
â”‚       â”‚   â””â”€â”€ page.tsx          
â”‚       â”œâ”€â”€ settings/             # í™˜ê²½ ì„¤ì •
â”‚       â”‚   â””â”€â”€ page.tsx          
â”‚       â””â”€â”€ help/                 # ë„ì›€ë§
â”‚           â””â”€â”€ page.tsx          
```

### ì»´í¬ë„ŒíŠ¸ êµ¬ì¡°
```
components/                       # ì¬ì‚¬ìš© ì»´í¬ë„ŒíŠ¸
â”œâ”€â”€ ui/                          # shadcn/ui ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸
â”‚   â”œâ”€â”€ button.tsx
â”‚   â”œâ”€â”€ input.tsx
â”‚   â”œâ”€â”€ dialog.tsx
â”‚   â”œâ”€â”€ table.tsx
â”‚   â””â”€â”€ chart.tsx
â”œâ”€â”€ layout/                      # ë ˆì´ì•„ì›ƒ ì»´í¬ë„ŒíŠ¸
â”‚   â”œâ”€â”€ header.tsx
â”‚   â”œâ”€â”€ sidebar.tsx
â”‚   â”œâ”€â”€ breadcrumb.tsx
â”‚   â””â”€â”€ footer.tsx
â”œâ”€â”€ data/                        # ë°ì´í„° ê´€ë ¨
â”‚   â”œâ”€â”€ data-table.tsx
â”‚   â”œâ”€â”€ file-upload.tsx
â”‚   â”œâ”€â”€ data-preview.tsx
â”‚   â””â”€â”€ data-validator.tsx
â”œâ”€â”€ analysis/                    # ë¶„ì„ ê´€ë ¨
â”‚   â”œâ”€â”€ analysis-wizard.tsx
â”‚   â”œâ”€â”€ test-selector.tsx
â”‚   â”œâ”€â”€ assumptions-checker.tsx
â”‚   â””â”€â”€ results-viewer.tsx
â”œâ”€â”€ charts/                      # ì‹œê°í™” ì»´í¬ë„ŒíŠ¸
â”‚   â”œâ”€â”€ histogram.tsx
â”‚   â”œâ”€â”€ boxplot.tsx
â”‚   â”œâ”€â”€ scatterplot.tsx
â”‚   â”œâ”€â”€ qqplot.tsx
â”‚   â””â”€â”€ interaction-plot.tsx
â””â”€â”€ forms/                       # í¼ ì»´í¬ë„ŒíŠ¸
    â”œâ”€â”€ analysis-form.tsx
    â”œâ”€â”€ options-form.tsx
    â””â”€â”€ export-form.tsx
```

## ìƒíƒœ ê´€ë¦¬ ì•„í‚¤í…ì²˜

### Zustand Store êµ¬ì¡°
```typescript
// stores/app-store.ts
interface AppStore {
  // ë°ì´í„° ìƒíƒœ
  data: {
    raw: DataSet | null
    processed: ProcessedData | null
    columns: ColumnInfo[]
    rowCount: number
  }
  
  // ë¶„ì„ ìƒíƒœ
  analysis: {
    type: AnalysisType
    options: AnalysisOptions
    results: AnalysisResults | null
    isRunning: boolean
    progress: number
  }
  
  // UI ìƒíƒœ
  ui: {
    theme: 'light' | 'dark'
    sidebarOpen: boolean
    activeView: string
    loading: boolean
  }
  
  // ì•¡ì…˜ë“¤
  actions: {
    setData: (data: DataSet) => void
    runAnalysis: (type: AnalysisType, options: AnalysisOptions) => Promise<void>
    toggleTheme: () => void
    setLoading: (loading: boolean) => void
  }
}
```

### TanStack Query êµ¬ì„±
```typescript
// hooks/queries.ts
export const queryKeys = {
  pyodide: ['pyodide'] as const,
  analysis: (type: string) => ['analysis', type] as const,
  data: (id: string) => ['data', id] as const,
} as const

// Pyodide ë¡œë”©
export const usePyodideQuery = () => 
  useQuery({
    queryKey: queryKeys.pyodide,
    queryFn: loadPyodide,
    staleTime: Infinity, // í•œë²ˆ ë¡œë“œë˜ë©´ ìºì‹œ ìœ ì§€
  })

// ë¶„ì„ ì‹¤í–‰
export const useAnalysisMutation = () => 
  useMutation({
    mutationFn: runPythonAnalysis,
    onSuccess: (results) => {
      // ê²°ê³¼ë¥¼ ìƒíƒœì— ì €ì¥
    }
  })
```

## Pyodide í†µê³„ ì—”ì§„

### âš ï¸ ê·¹íˆ ì¤‘ìš”: ëª¨ë“  í†µê³„ ê³„ì‚°ì€ ë°˜ë“œì‹œ Pyodide + SciPy ì‚¬ìš©
**ì ˆëŒ€ JavaScript/TypeScriptë¡œ í†µê³„ í•¨ìˆ˜ë¥¼ ì§ì ‘ êµ¬í˜„í•˜ì§€ ë§ˆì„¸ìš”!**
- âœ… ì˜¬ë°”ë¥¸ ë°©ë²•: Pyodideë¥¼ í†µí•´ SciPy ì‚¬ìš©
- âŒ ì˜ëª»ëœ ë°©ë²•: JavaScriptë¡œ í†µê³„ ê³µì‹ êµ¬í˜„
- ì´ìœ : ì •í™•ë„, ì‹ ë¢°ì„±, ê²€ì¦ëœ ì•Œê³ ë¦¬ì¦˜

### Python í†µê³„ ëª¨ë“ˆ êµ¬ì¡°
```python
# pyodide/statistical_engine.py
import scipy.stats as stats
import numpy as np
import pandas as pd
from typing import Dict, List, Any, Tuple

class StatisticalEngine:
    """í†µê³„ ë¶„ì„ ì—”ì§„ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.data = None
        self.results = {}
    
    # ê¸°ìˆ í†µê³„
    def descriptive_stats(self, data: np.ndarray) -> Dict:
        return {
            'mean': np.mean(data),
            'std': np.std(data, ddof=1),
            'median': np.median(data),
            'q1': np.percentile(data, 25),
            'q3': np.percentile(data, 75),
            'skewness': stats.skew(data),
            'kurtosis': stats.kurtosis(data),
            'ci_95': stats.t.interval(0.95, len(data)-1, 
                                    np.mean(data), 
                                    stats.sem(data))
        }
    
    # ê°€ì • ê²€ì •
    def test_normality(self, data: np.ndarray) -> Dict:
        """ì •ê·œì„± ê²€ì •"""
        if len(data) < 3:
            return {'error': 'Insufficient data'}
        
        if len(data) <= 50:
            stat, p = stats.shapiro(data)
            test_name = 'Shapiro-Wilk'
        else:
            stat, p = stats.kstest(data, 'norm')
            test_name = 'Kolmogorov-Smirnov'
        
        return {
            'test': test_name,
            'statistic': stat,
            'p_value': p,
            'is_normal': p > 0.05,
            'alpha': 0.05
        }
    
    def test_homogeneity(self, *groups) -> Dict:
        """ë“±ë¶„ì‚°ì„± ê²€ì •"""
        # Levene's test
        stat_levene, p_levene = stats.levene(*groups)
        
        # Bartlett's test (ì •ê·œë¶„í¬ ê°€ì •)
        stat_bartlett, p_bartlett = stats.bartlett(*groups)
        
        return {
            'levene': {
                'statistic': stat_levene,
                'p_value': p_levene,
                'is_homogeneous': p_levene > 0.05
            },
            'bartlett': {
                'statistic': stat_bartlett,
                'p_value': p_bartlett,
                'is_homogeneous': p_bartlett > 0.05
            }
        }
    
    # ê¸°ë³¸ ê²€ì •
    def t_test_independent(self, group1: np.ndarray, group2: np.ndarray, 
                          equal_var: bool = True) -> Dict:
        """ë…ë¦½í‘œë³¸ t-ê²€ì •"""
        if equal_var:
            stat, p = stats.ttest_ind(group1, group2)
            test_type = "Independent t-test"
        else:
            stat, p = stats.ttest_ind(group1, group2, equal_var=False)
            test_type = "Welch's t-test"
        
        # Cohen's d ê³„ì‚°
        pooled_std = np.sqrt(((len(group1)-1)*np.var(group1, ddof=1) + 
                             (len(group2)-1)*np.var(group2, ddof=1)) / 
                             (len(group1)+len(group2)-2))
        cohens_d = (np.mean(group1) - np.mean(group2)) / pooled_std
        
        return {
            'test_type': test_type,
            'statistic': stat,
            'p_value': p,
            'degrees_of_freedom': len(group1) + len(group2) - 2,
            'effect_size': {
                'cohens_d': cohens_d,
                'interpretation': self._interpret_cohens_d(cohens_d)
            },
            'means': {
                'group1': np.mean(group1),
                'group2': np.mean(group2),
                'difference': np.mean(group1) - np.mean(group2)
            }
        }
    
    # ANOVA
    def one_way_anova(self, *groups) -> Dict:
        """ì¼ì›ë¶„ì‚°ë¶„ì„"""
        # ê¸°ë³¸ ANOVA
        f_stat, p_value = stats.f_oneway(*groups)
        
        # ê·¸ë£¹ë³„ í†µê³„
        group_stats = []
        for i, group in enumerate(groups):
            group_stats.append({
                'group': f'Group_{i+1}',
                'n': len(group),
                'mean': np.mean(group),
                'std': np.std(group, ddof=1),
                'se': stats.sem(group)
            })
        
        # íš¨ê³¼í¬ê¸° (eta-squared)
        ss_total = sum(np.sum((group - np.mean(np.concatenate(groups)))**2) 
                      for group in groups)
        ss_within = sum(np.sum((group - np.mean(group))**2) 
                       for group in groups)
        eta_squared = (ss_total - ss_within) / ss_total
        
        result = {
            'test_type': 'One-way ANOVA',
            'f_statistic': f_stat,
            'p_value': p_value,
            'degrees_of_freedom': {
                'between': len(groups) - 1,
                'within': sum(len(g) for g in groups) - len(groups),
                'total': sum(len(g) for g in groups) - 1
            },
            'effect_size': {
                'eta_squared': eta_squared,
                'interpretation': self._interpret_eta_squared(eta_squared)
            },
            'group_statistics': group_stats,
            'significant': p_value < 0.05
        }
        
        # ìœ ì˜í•˜ë©´ ì‚¬í›„ë¶„ì„ ìˆ˜í–‰
        if p_value < 0.05:
            result['post_hoc'] = self.post_hoc_tukey(*groups)
        
        return result
    
    def post_hoc_tukey(self, *groups) -> Dict:
        """Tukey HSD ì‚¬í›„ë¶„ì„"""
        from itertools import combinations
        
        # ëª¨ë“  ìŒë³„ ë¹„êµ
        comparisons = []
        group_names = [f'Group_{i+1}' for i in range(len(groups))]
        
        for i, j in combinations(range(len(groups)), 2):
            group1, group2 = groups[i], groups[j]
            
            # Tukey HSD ê³„ì‚°
            n1, n2 = len(group1), len(group2)
            mean1, mean2 = np.mean(group1), np.mean(group2)
            
            # MSE ê³„ì‚° (ëª¨ë“  ê·¸ë£¹ í¬í•¨)
            all_data = np.concatenate(groups)
            grand_mean = np.mean(all_data)
            ss_within = sum(np.sum((group - np.mean(group))**2) 
                           for group in groups)
            df_within = sum(len(g) for g in groups) - len(groups)
            mse = ss_within / df_within
            
            # Tukey HSD í†µê³„ëŸ‰
            se = np.sqrt(mse * (1/n1 + 1/n2) / 2)
            q_stat = (mean1 - mean2) / se
            
            # p-valueëŠ” ê·¼ì‚¬ì¹˜ (ì •í™•í•œ ê³„ì‚°ì„ ìœ„í•´ì„œëŠ” studentized range distribution í•„ìš”)
            p_value = 2 * (1 - stats.norm.cdf(abs(q_stat)))
            
            comparisons.append({
                'groups': f'{group_names[i]} vs {group_names[j]}',
                'mean_difference': mean1 - mean2,
                'se': se,
                'q_statistic': q_stat,
                'p_value': p_value,
                'significant': p_value < 0.05
            })
        
        return {
            'method': 'Tukey HSD',
            'comparisons': comparisons,
            'alpha': 0.05
        }
    
    # ë¹„ëª¨ìˆ˜ ê²€ì •
    def mann_whitney_u(self, group1: np.ndarray, group2: np.ndarray) -> Dict:
        """Mann-Whitney U ê²€ì •"""
        stat, p = stats.mannwhitneyu(group1, group2, alternative='two-sided')
        
        # íš¨ê³¼í¬ê¸° (r)
        n1, n2 = len(group1), len(group2)
        z_score = stats.norm.ppf(p/2)  # ê·¼ì‚¬ì¹˜
        r = abs(z_score) / np.sqrt(n1 + n2)
        
        return {
            'test_type': 'Mann-Whitney U test',
            'u_statistic': stat,
            'p_value': p,
            'effect_size': {
                'r': r,
                'interpretation': self._interpret_r(r)
            },
            'medians': {
                'group1': np.median(group1),
                'group2': np.median(group2)
            }
        }
    
    def kruskal_wallis(self, *groups) -> Dict:
        """Kruskal-Wallis ê²€ì •"""
        stat, p = stats.kruskal(*groups)
        
        result = {
            'test_type': 'Kruskal-Wallis H test',
            'h_statistic': stat,
            'p_value': p,
            'degrees_of_freedom': len(groups) - 1,
            'significant': p < 0.05
        }
        
        # ìœ ì˜í•˜ë©´ Dunn's test ìˆ˜í–‰
        if p < 0.05:
            result['post_hoc'] = self.post_hoc_dunn(*groups)
        
        return result
    
    def post_hoc_dunn(self, *groups) -> Dict:
        """Dunn's test ì‚¬í›„ë¶„ì„"""
        from itertools import combinations
        
        # ì „ì²´ ë°ì´í„° ìˆœìœ„ ê³„ì‚°
        all_data = np.concatenate(groups)
        ranks = stats.rankdata(all_data)
        
        # ê·¸ë£¹ë³„ ìˆœìœ„ í•©
        group_rank_sums = []
        start_idx = 0
        for group in groups:
            end_idx = start_idx + len(group)
            rank_sum = np.sum(ranks[start_idx:end_idx])
            group_rank_sums.append(rank_sum)
            start_idx = end_idx
        
        n = len(all_data)
        comparisons = []
        
        for i, j in combinations(range(len(groups)), 2):
            n1, n2 = len(groups[i]), len(groups[j])
            R1, R2 = group_rank_sums[i], group_rank_sums[j]
            
            # Dunn's test í†µê³„ëŸ‰
            se = np.sqrt((n * (n + 1) / 12) * (1/n1 + 1/n2))
            z_stat = (R1/n1 - R2/n2) / se
            p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))
            
            comparisons.append({
                'groups': f'Group_{i+1} vs Group_{j+1}',
                'z_statistic': z_stat,
                'p_value': p_value,
                'significant': p_value < 0.05
            })
        
        return {
            'method': 'Dunn\'s test',
            'comparisons': comparisons,
            'alpha': 0.05
        }
    
    # í•´ì„ í•¨ìˆ˜ë“¤
    def _interpret_cohens_d(self, d: float) -> str:
        """Cohen's d í•´ì„"""
        abs_d = abs(d)
        if abs_d < 0.2:
            return 'negligible'
        elif abs_d < 0.5:
            return 'small'
        elif abs_d < 0.8:
            return 'medium'
        else:
            return 'large'
    
    def _interpret_eta_squared(self, eta: float) -> str:
        """Eta-squared í•´ì„"""
        if eta < 0.01:
            return 'negligible'
        elif eta < 0.06:
            return 'small'
        elif eta < 0.14:
            return 'medium'
        else:
            return 'large'
    
    def _interpret_r(self, r: float) -> str:
        """íš¨ê³¼í¬ê¸° r í•´ì„"""
        if r < 0.1:
            return 'negligible'
        elif r < 0.3:
            return 'small'
        elif r < 0.5:
            return 'medium'
        else:
            return 'large'

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
engine = StatisticalEngine()

# JavaScriptì—ì„œ í˜¸ì¶œí•  í•¨ìˆ˜ë“¤
def run_descriptive_analysis(data_json: str) -> str:
    """ê¸°ìˆ í†µê³„ ë¶„ì„"""
    import json
    data = np.array(json.loads(data_json))
    result = engine.descriptive_stats(data)
    return json.dumps(result, cls=NumpyEncoder)

def run_t_test(group1_json: str, group2_json: str, equal_var: bool = True) -> str:
    """t-ê²€ì •"""
    import json
    group1 = np.array(json.loads(group1_json))
    group2 = np.array(json.loads(group2_json))
    result = engine.t_test_independent(group1, group2, equal_var)
    return json.dumps(result, cls=NumpyEncoder)

def run_anova(*groups_json) -> str:
    """ì¼ì›ë¶„ì‚°ë¶„ì„"""
    import json
    groups = [np.array(json.loads(group)) for group in groups_json]
    result = engine.one_way_anova(*groups)
    return json.dumps(result, cls=NumpyEncoder)

# JSON ì§ë ¬í™”ìš© í´ë˜ìŠ¤
class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        if isinstance(obj, np.floating):
            return float(obj)
        if isinstance(obj, np.integer):
            return int(obj)
        return super().default(obj)
```

### Web Workers í†µí•©
```typescript
// lib/workers/pyodide-worker.ts
self.onmessage = async (event) => {
  const { type, data } = event.data
  
  try {
    switch (type) {
      case 'LOAD_PYODIDE':
        await loadPyodide()
        self.postMessage({ type: 'PYODIDE_LOADED' })
        break
        
      case 'RUN_ANALYSIS':
        const results = await runPythonFunction(data.funcName, data.args)
        self.postMessage({ 
          type: 'ANALYSIS_COMPLETE', 
          data: results 
        })
        break
        
      default:
        throw new Error(`Unknown message type: ${type}`)
    }
  } catch (error) {
    self.postMessage({ 
      type: 'ERROR', 
      error: error.message 
    })
  }
}
```

## ë°ì´í„° ì²˜ë¦¬ ì•„í‚¤í…ì²˜

### íŒŒì¼ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
```typescript
// lib/data-processing.ts
export class DataProcessor {
  static async processFile(file: File): Promise<ProcessedData> {
    // 1. íŒŒì¼ íƒ€ì… ê²€ì¦
    const fileType = this.detectFileType(file)
    
    // 2. íŒŒì‹±
    const rawData = await this.parseFile(file, fileType)
    
    // 3. ê²€ì¦
    const validationResult = this.validateData(rawData)
    
    // 4. ì „ì²˜ë¦¬
    const processedData = this.preprocessData(rawData, validationResult)
    
    return processedData
  }
  
  private static detectFileType(file: File): 'csv' | 'xlsx' | 'json' {
    const extension = file.name.split('.').pop()?.toLowerCase()
    // íŒŒì¼ íƒ€ì… ê°ì§€ ë¡œì§
  }
  
  private static async parseFile(file: File, type: string): Promise<RawData> {
    switch (type) {
      case 'csv':
        return this.parseCSV(file)
      case 'xlsx':
        return this.parseExcel(file)
      default:
        throw new Error('Unsupported file type')
    }
  }
  
  private static validateData(data: RawData): ValidationResult {
    return {
      isValid: true,
      errors: [],
      warnings: [],
      suggestions: []
    }
  }
}
```

## ì„±ëŠ¥ ìµœì í™”

### ë©”ëª¨ë¦¬ ê´€ë¦¬
```typescript
// lib/memory-manager.ts
export class MemoryManager {
  private static instance: MemoryManager
  private pyodideInstance: any
  
  static getInstance(): MemoryManager {
    if (!this.instance) {
      this.instance = new MemoryManager()
    }
    return this.instance
  }
  
  async cleanupPython(): Promise<void> {
    if (this.pyodideInstance) {
      await this.pyodideInstance.runPython(`
        import gc
        gc.collect()
      `)
    }
  }
  
  async monitorMemory(): Promise<MemoryInfo> {
    const memInfo = (performance as any).memory
    return {
      usedJSHeapSize: memInfo.usedJSHeapSize,
      totalJSHeapSize: memInfo.totalJSHeapSize,
      jsHeapSizeLimit: memInfo.jsHeapSizeLimit
    }
  }
}
```

### ìºì‹± ì „ëµ
```typescript
// lib/cache-manager.ts
export class CacheManager {
  private cache = new Map<string, CacheEntry>()
  
  async get<T>(key: string): Promise<T | null> {
    const entry = this.cache.get(key)
    if (!entry || this.isExpired(entry)) {
      return null
    }
    return entry.data as T
  }
  
  async set<T>(key: string, data: T, ttl: number = 300000): Promise<void> {
    this.cache.set(key, {
      data,
      timestamp: Date.now(),
      ttl
    })
  }
  
  private isExpired(entry: CacheEntry): boolean {
    return Date.now() - entry.timestamp > entry.ttl
  }
}
```

---

## ë³´ì•ˆ ë° ì•ˆì •ì„±

### CSP (Content Security Policy)
```typescript
// next.config.js
const nextConfig = {
  async headers() {
    return [
      {
        source: '/(.*)',
        headers: [
          {
            key: 'Content-Security-Policy',
            value: `
              default-src 'self';
              script-src 'self' 'unsafe-eval' 'unsafe-inline' blob:;
              worker-src 'self' blob:;
              child-src 'self' blob:;
              connect-src 'self' data: blob:;
              img-src 'self' data: blob:;
              style-src 'self' 'unsafe-inline';
              font-src 'self' data:;
            `.replace(/\s+/g, ' ').trim()
          }
        ]
      }
    ]
  }
}
```

### ì—ëŸ¬ ì²˜ë¦¬
```typescript
// lib/error-handler.ts
export class ErrorHandler {
  static handle(error: Error, context: string): void {
    // ë¡œê¹…
    console.error(`[${context}] ${error.message}`, error)
    
    // ì‚¬ìš©ì ì•Œë¦¼
    if (error instanceof PyodideError) {
      // Pyodide íŠ¹í™” ì—ëŸ¬ ì²˜ë¦¬
    } else if (error instanceof DataValidationError) {
      // ë°ì´í„° ê²€ì¦ ì—ëŸ¬ ì²˜ë¦¬
    }
    
    // ë³µêµ¬ ì‹œë„
    this.attemptRecovery(error, context)
  }
  
  private static attemptRecovery(error: Error, context: string): void {
    // ìë™ ë³µêµ¬ ë¡œì§
  }
}
```

ì´ ê¸°ìˆ  ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²¬ê³ í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ í†µê³„ ë¶„ì„ í”Œë«í¼ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ê¸°ìˆ  ìŠ¤íƒ

### Core Technologies
| Layer | Technology | Version | ìš©ë„ |
|-------|-----------|---------|-----|
| Frontend | Next.js | 15.5.2 | React 19 í”„ë ˆì„ì›Œí¬ |
| Language | TypeScript | 5.7.3 | íƒ€ì… ì•ˆì „ì„± |
| UI Components | shadcn/ui | Latest | ì „ë¬¸ê°€ê¸‰ UI ì»´í¬ë„ŒíŠ¸ |
| Styling | Tailwind CSS | 3.4.0 | ìœ í‹¸ë¦¬í‹° CSS |
| State | Zustand | 5.0.3 | ì „ì—­ ìƒíƒœ ê´€ë¦¬ |
| Query | TanStack Query | 5.65.0 | ì„œë²„ ìƒíƒœ ê´€ë¦¬ |
| Charts | Recharts | 2.15.0 | ë°ì´í„° ì‹œê°í™” |
| Icons | Lucide React | 0.476.0 | ì•„ì´ì½˜ ì‹œìŠ¤í…œ |
| Python Runtime | Pyodide | 0.26.4 | WebAssembly Python |
| Desktop | Tauri | 2.0 (ì˜ˆì •) | í¬ë¡œìŠ¤í”Œë«í¼ ë°ìŠ¤í¬íƒ‘ |

### Statistical Libraries (Pyodide)
| Library | Version | ìš©ë„ |
|---------|---------|------|
| scipy | 1.14.1 | í†µê³„ í•¨ìˆ˜ |
| numpy | 2.2.1 | ìˆ˜ì¹˜ ê³„ì‚° |
| pandas | 2.2.3 | ë°ì´í„° ì²˜ë¦¬ |
| statsmodels | 0.14.6 | ê³ ê¸‰ í†µê³„ |
| scikit-learn | 1.6.1 | ë¨¸ì‹ ëŸ¬ë‹ (ì„ íƒì ) |

### Development Tools
| Tool | Version | ìš©ë„ |
|------|---------|------|
| Node.js | 20.x | JavaScript ëŸ°íƒ€ì„ |
| npm | 10.x | íŒ¨í‚¤ì§€ ê´€ë¦¬ |
| ESLint | 9.x | ì½”ë“œ í’ˆì§ˆ |
| Prettier | 3.x | ì½”ë“œ í¬ë§·íŒ… |
| Jest | 29.x | í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ |
| Testing Library | 16.x | ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸ |

---

*ìµœì¢… ì—…ë°ì´íŠ¸: 2025-09-12*